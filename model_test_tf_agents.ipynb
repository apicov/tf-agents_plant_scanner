{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], \n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=256)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_logical_devices('GPU')\n",
    "\n",
    "import tf_agents\n",
    "from tf_agents.environments import py_environment, parallel_py_environment, batched_py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.networks.q_network import QNetwork\n",
    "from tf_agents.agents.dqn.dqn_agent import DqnAgent\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.metrics import tf_metrics\n",
    "#from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver\n",
    "from tf_agents.drivers.dynamic_episode_driver import DynamicEpisodeDriver\n",
    "from tf_agents.policies.random_tf_policy import RandomTFPolicy\n",
    "from tf_agents.utils.common import function, element_wise_squared_loss\n",
    "from tf_agents.eval.metric_utils import log_metrics\n",
    "from tf_agents.policies import policy_saver\n",
    "import logging\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "from scan_gym import envs\n",
    "seed=42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "import imp\n",
    "#import test as nntools\n",
    "#imp.reload(nntools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "'''envs_paths = [os.path.join(current_path, 'plants_dataset/scan_plant001/v01/inliers_ratios.npy'),\n",
    "                os.path.join(current_path, 'plants_dataset/scan_plant002/v01/inliers_ratios.npy'),\n",
    "                os.path.join(current_path, 'plants_dataset/scan_plant003/v01/inliers_ratios.npy'),\n",
    "                os.path.join(current_path, 'plants_dataset/scan_plant004/v01/inliers_ratios.npy'),\n",
    "                os.path.join(current_path, 'plants_dataset/scan_plant005/v01/inliers_ratios.npy'),\n",
    "                os.path.join(current_path, 'plants_dataset/scan_plant006/v01/inliers_ratios.npy')\n",
    "                ]'''\n",
    "\n",
    "envs_paths = [os.path.join(current_path, 'plants_dataset/real_plant001/v01/inliers_ratios.npy'),\n",
    "                os.path.join(current_path, 'plants_dataset/real_plant001/v03/inliers_ratios.npy'),\n",
    "                os.path.join(current_path, 'plants_dataset/real_plant002/v01/inliers_ratios.npy')]\n",
    "\n",
    "envs = [suite_gym.load('ScannerEnv-v0',\n",
    "        gym_kwargs={'setpoint':0.03,'init_pos_inc_rst':True,'inliers_ratios_file':os.path.join(current_path,x)}) for x in envs_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_dir = os.path.join(current_path, 'policy')\n",
    "policy = tf.compat.v2.saved_model.load(policy_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#custom observer\n",
    "class testData:\n",
    "    def __init__(self):\n",
    "        self.episodes = []\n",
    "        self.episode = []\n",
    "        self.counter = 0\n",
    "    def __call__(self, trajectory):\n",
    "        self.episode.append(trajectory)\n",
    "        if trajectory.is_last():\n",
    "            self.episodes.append(copy.deepcopy(self.episode))\n",
    "            self.episode = []\n",
    "            print('cucu')\n",
    "\n",
    "test_data = testData()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_driver = DynamicEpisodeDriver(\n",
    "    tf_env,\n",
    "    policy,\n",
    "    observers=[test_data],\n",
    "    num_episodes=1440) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_driver.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(tf_env,env,policy):\n",
    "    state = tf_env.reset()\n",
    "    last_position = env.current_position\n",
    "    cont = 0\n",
    "    time_steps = 3000\n",
    "    #obs = deque(maxlen=time_steps)\n",
    "\n",
    "    for i in range(time_steps):\n",
    "        #obs.append(state.observation[0].numpy())\n",
    "        cont +=1\n",
    "        action_step = policy.action(state)\n",
    "        next_state = tf_env.step(action_step.action)\n",
    "        #print(cont,':',last_position,state.observation[0].numpy(),   env.action2move(action_step.action.numpy(),state.observation[0][-1].numpy()),state.step_type.numpy()  )#,env.action2move(action_step.action,state.observation[0][-1].numpy()))#action,dir\n",
    "        state = copy.deepcopy(next_state)\n",
    "        last_position = env.current_position\n",
    "        if state.is_last():\n",
    "            #print('salio',cont)\n",
    "            break    \n",
    "    return env.kept_images,env.total_reward,env.num_steps,env.covered_area\n",
    "\n",
    "\n",
    "def test_model(tf_env,env,policy,match_indexes):\n",
    "    data = []\n",
    "    for i in np.arange(0,1440):#range(1440):\n",
    "        images,t_reward,n_steps,covered_area = run_episode(tf_env,env,policy)\n",
    "        #######score = get_imageset_error(images,match_indexes,30,covered_area/36)\n",
    "        #score,stdd= get_error(images,match_indexes,setpoint,covered_area/36)\n",
    "        score, stdd = get_idx_stats(match_indexes,images)\n",
    "        print(\"\\rEpisode {} \".format(i),end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        #######score = get_image_set_score(images,match_indexes)\n",
    "        data.append([score,stdd,len(images),t_reward,n_steps,env.total_moves,covered_area])\n",
    "    return np.array(data)\n",
    "\n",
    "def test_models(envs,m_idxs,model,scaler=None):\n",
    "    cdata = []\n",
    "    cstats = []\n",
    "    tf_envs = [tf_py_environment.TFPyEnvironment(env) for env in envs]\n",
    "    \n",
    "    for i in range(len(envs)):\n",
    "        env = envs[i]\n",
    "        tf_env = tf_envs[i]\n",
    "        match_indexes = np.load(m_idxs[i])\n",
    "    \n",
    "        dt = test_model(tf_env,env,policy,match_indexes)\n",
    "        st = get_stats(dt)\n",
    "        print(i,':',st)\n",
    "        cdata.append(dt)\n",
    "        cstats.append(st)\n",
    "    return cdata,cstats\n",
    "    \n",
    "def get_error(image_set,idx_table,setpoint,coverage_fraction):\n",
    "    ordered = sorted(image_set)\n",
    "    errors = []\n",
    "    for i in range(len(image_set)):\n",
    "        error = abs(idx_table[ordered[i],ordered[i-1]] - setpoint)\n",
    "        errors.append(error)\n",
    "    return (np.mean(errors)*(coverage_fraction)) + (1-coverage_fraction), np.std(errors)\n",
    "\n",
    "def get_stats(data):\n",
    "    score = np.mean(data[:,0])\n",
    "    std = np.mean(data[:,1])\n",
    "    n_images = np.mean(data[:,2])\n",
    "    reward = np.mean(data[:,3])\n",
    "    n_steps = np.mean(data[:,4])\n",
    "    total_moves = np.mean(data[:,5])\n",
    "    covered_area = np.mean(data[:,6])\n",
    "    #how many did not covered he whole area\n",
    "    n_incomplete = len(data[:,6][ data[:,6] < 8])\n",
    "    return [score,std,n_images,reward,n_steps,total_moves,covered_area,n_incomplete]\n",
    "\n",
    "def get_idx_stats(idx_table,image_set):\n",
    "    ordered = sorted(image_set)\n",
    "    idxs = []\n",
    "    for i in range(len(image_set)):\n",
    "        idx = idx_table[ordered[i],ordered[i-1]]\n",
    "        idxs.append(idx)\n",
    "    return np.mean(idxs),np.std(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt,st = test_models(envs,envs_paths,policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['mean_idx','std','n_images','score','total_steps','n_movements','covered_area','n_incomplete']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
